defaults:
  - _self_
  - rewards:
    - action_penalty
    - object_pos_err
    - hand_joint_pos_err
    - reach_bonus

name: repose_task

env:
  _target_: warp.envs.ReposeTask
  num_envs: ${resolve_default:256,${num_envs}}
  episode_length: 500
  render: ${render}
  reward_params: 
    action_penalty: ${...rewards.action_penalty}
    object_pos_err: ${...rewards.object_pos_err}
    hand_joint_pos_err: ${...rewards.hand_joint_pos_err}
    reach_bonus: ${...rewards.reach_bonus}
  hand_start_orientation: ${eval:'(-np.pi / 2 * 3, np.pi * 0.75, np.pi / 2 * 3)'}
  hand_start_position: ${eval:'(0.0, 0.3, 0.0)'}
  stochastic_init: false
  render_mode: ${render:none}
  use_autograd: true
  use_graph_capture: true


ppo:
  max_epochs: 5000
  save_best_after: 100
  save_frequency: 400
  num_actors: 2048
  minibatch_size: 16384
  steps_num: 32
  actor_mlp:
    units: [64, 64]

player:
  deterministic: true
  games_num: 100000
  print_stats: true
