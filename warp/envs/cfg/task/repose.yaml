defaults:
  - _self_
  - rewards:
    - action_penalty
    - action_pose_err
    - object_pos_err
    - reach_bonus
    - rot_reward_delta
    - rot_reward
    - hand_joint_pos_err

name: repose_task

score_keys:
  - object_rot_diff
  - object_pos_err
  - reach_bonus
  - action_penalty
  - net_energy

env:
  _target_: warp.envs.ReposeTask
  num_envs: ${resolve_default:1024,${num_envs}}
  episode_length: 250
  render: ${render}
  reward_params: 
    # action_penalty: ${task.rewards.action_penalty}
    action_pose_err: ${task.rewards.action_pose_err}
    object_pos_err: ${task.rewards.object_pos_err}
    # hand_joint_pos_err: ${task.rewards.hand_joint_pos_err}
    rot_reward_delta: ${task.rewards.rot_reward_delta}
    rot_reward: ${task.rewards.rot_reward}
    reach_bonus: ${task.rewards.reach_bonus}
  hand_type: ${hand:allegro}
  stochastic_init: true
  use_autograd: true
  use_graph_capture: false
  reach_threshold: 0.1  # radians from goal rotation considered success
  # use_graph_capture: ${eval:'("shac" not in "${alg.name}")'}
  no_grad: ???


ppo:
  max_epochs: 1000
  save_best_after: 100
  save_frequency: 400
  num_actors: 1024
  minibatch_size: 8192
  steps_num: 32
  actor_mlp:
    units: [64, 64]
  score_to_win: 60000

player:
  deterministic: true
  games_num: 5
  print_stats: true
